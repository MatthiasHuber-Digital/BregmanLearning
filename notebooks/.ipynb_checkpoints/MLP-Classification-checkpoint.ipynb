{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Various torch packages\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# torchvision\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# ------------------------\n",
    "# get up one directory \n",
    "import sys, os\n",
    "sys.path.append(os.path.abspath('../'))\n",
    "# ------------------------\n",
    "\n",
    "# custom packages\n",
    "import models.aux_funs as maf\n",
    "import optimizers as op\n",
    "import regularizers as reg\n",
    "import train\n",
    "import math\n",
    "import utils.configuration as cf\n",
    "import utils.datasets as ud\n",
    "from models.fully_connected import fully_connected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fix the random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 2\n",
    "cf.seed_torch(random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configure the experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sparse_init = 0.01\n",
    "r = [1,0.7/math.sqrt(sparse_init)]\n",
    "\n",
    "conf_args = {#\n",
    "    # data specification\n",
    "    'data_file':\"../../Data\", 'train_split' : 0.95, 'data_set':\"MNIST\", 'download':False,\n",
    "    # cuda\n",
    "    'use_cuda': True, 'num_workers':4, 'cuda_device':0, 'pin_memory':True, 'train_split':0.95,\n",
    "    #\n",
    "    'epochs':100,\n",
    "    # optimizer\n",
    "    'delta': 1.0, 'lr': 0.1, 'mu': 1e-3, 'optim':\"LinBreg\",'beta':0.0,\n",
    "    # initialization\n",
    "    'sparse_init':sparse_init, 'r':r,\n",
    "    # misc\n",
    "    'random_seed':random_seed, 'eval_acc':True,\n",
    "}\n",
    "\n",
    "conf = cf.Conf(**conf_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initiate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model_kwargs = {'mean':conf.data_set_mean, 'std':conf.data_set_std}    \n",
    "\n",
    "sizes = [784, 200, 80, 10]\n",
    "act_fun = torch.nn.ReLU()\n",
    "    \n",
    "model = fully_connected(sizes, act_fun, **model_kwargs)\n",
    "best_model = train.best_model(fully_connected(sizes, act_fun, **model_kwargs).to(conf.device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weight initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_kwargs = {'mean':conf.data_set_mean, 'std':conf.data_set_std}    \n",
    "def init_weights(conf, model):\n",
    "    # sparsify\n",
    "    maf.sparse_bias_uniform_(model, 0,conf.r[0])\n",
    "    maf.sparse_weight_normal_(model, conf.r[1])\n",
    "    \n",
    "    maf.sparsify_(model, conf.sparse_init)\n",
    "    model = model.to(conf.device)\n",
    "    return model\n",
    "\n",
    "model = init_weights(conf,model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def init_opt(conf, model):\n",
    "    weights_linear = maf.get_weights_linear(model)\n",
    "    biases = maf.get_bias(model)\n",
    "\n",
    "    if conf.optim == \"SGD\":\n",
    "        opt = torch.optim.SGD(model.parameters(), lr=conf.lr, momentum=conf.beta)\n",
    "    elif conf.optim == \"LinBreg\":\n",
    "        opt = op.LinBreg([{'params': weights_linear, 'lr' : conf.lr, 'reg' : reg.reg_l1(mu=conf.mu), 'momentum':conf.beta, 'delta':conf.delta},\n",
    "                          {'params': biases, 'lr': conf.lr, 'momentum':conf.beta}])\n",
    "    elif conf.optim == \"adam\":\n",
    "        opt = op.AdamBreg([{'params': weights_linear, 'lr' : conf.lr, 'reg' : reg.reg_l1(mu=conf.mu)},\n",
    "                          {'params': biases, 'lr': conf.lr}])\n",
    "    elif conf.optim == \"PSGD\":\n",
    "        opt = op.ProxSGD([{'params': weights_linear, 'lr' : conf.lr, 'reg' : reg.reg_l1(mu=conf.mu)},\n",
    "                          {'params': biases, 'lr': conf.lr}])\n",
    "    else:\n",
    "        raise ValueError(\"Unknown Optimizer specified\")\n",
    "\n",
    "    # learning rate scheduler\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(opt, factor=0.5, patience=5,threshold=0.01)\n",
    "    \n",
    "    return opt, scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, valid_loader, test_loader = ud.get_data_set(conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# History and Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize history\n",
    "tracked = ['loss', 'node_sparse']\n",
    "train_history = {key: [] for key in tracked}\n",
    "val_history = {key: [] for key in tracked}\n",
    "\n",
    "# Initialize runs\n",
    "runs = cf.run(**{'num_runs':0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "while runs.step():\n",
    "    # -----------------------------------------------------------------------------------\n",
    "    # Reinit weigts and the corresponding optimizer\n",
    "    # -----------------------------------------------------------------------------------\n",
    "    model = init_weights(conf, model)\n",
    "    opt, scheduler = init_opt(conf, model)\n",
    "    \n",
    "    # -----------------------------------------------------------------------------------\n",
    "    # train the model\n",
    "    # -----------------------------------------------------------------------------------\n",
    "    for epoch in range(conf.epochs):\n",
    "        print(25*\"<>\")\n",
    "        print(50*\"|\")\n",
    "        print(25*\"<>\")\n",
    "        print('Epoch:', epoch)\n",
    "\n",
    "        # ------------------------------------------------------------------------\n",
    "        # train step, log the accuracy and loss\n",
    "        # ------------------------------------------------------------------------\n",
    "        train_data = train.train_step(conf, model, opt, train_loader)\n",
    "\n",
    "        # update history\n",
    "        for key in tracked:\n",
    "            if key in train_data:\n",
    "                train_history[key].append(train_data[key])        \n",
    "\n",
    "        # ------------------------------------------------------------------------\n",
    "        # validation step\n",
    "        val_data = train.validation_step(conf, model, opt, valid_loader, opt_reg_eval=False)\n",
    "\n",
    "        # update history\n",
    "        for key in tracked:\n",
    "            if key in val_data:\n",
    "                val_history[key].append(val_data[key])\n",
    "\n",
    "        for i,reg_val in enumerate(val_data['node_sparse']):\n",
    "            key = \"node_sparse\" + str(i)\n",
    "            if key in val_history:\n",
    "                val_history[key].append(reg_val)\n",
    "            else:\n",
    "                val_history[key] = [reg_val]\n",
    "\n",
    "\n",
    "        scheduler.step(train_data['loss'])\n",
    "        print(\"Learning rate:\",opt.param_groups[0]['lr'])\n",
    "        best_model(train_data['acc'], val_data['acc'], model=model)\n",
    "\n",
    "        \n",
    "    # add values to the run history\n",
    "    runs.add_history(train_history, \"train\")\n",
    "    runs.add_history(val_history, \"val\")\n",
    "            \n",
    "    # update random seed\n",
    "    conf.random_seed += 1\n",
    "    cf.seed_torch(conf.random_seed)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
